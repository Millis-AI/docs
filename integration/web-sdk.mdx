---
title: 'Web SDK'
description: "Integrate Millis AI's voice agent capabilities directly into your web applications and browser extensions."
icon: 'code'
---

## Installation

Install the SDK with npm:

```
npm install @millisai/web-sdk
```

## Usage

Hereâ€™s how to quickly set up a voice agent in your web application:

### 1. Import the SDK:

```js
import Millis from '@millisai/web-sdk';
```

### 2. Initialize the Client:

```js
const msClient = Millis.createClient({publicKey: 'your_public_key'});
```

Obtain your public key from your [Millis AI Playground](https://app.millis.ai/settings/keys)

### 3. Start a Conversation:

#### Using a Predefined Agent

First, create a voice agent from the [Playground](https://app.millis.ai/agents). Then, start a conversation with your agent using the following code:

```js
msClient.start(<agent-id>, metadata?: {});
```

Replace `agent-id` with the ID of your agent obtained from the Playground.

The `metadata` is optional. You can pass any additional data to the session, which we will forward to your custom LLM and function webhooks.

#### Dynamically Creating a Temporary Voice Agent

You can also dynamically create a temporary voice agent with custom configurations using the code below:

```js
msClient.start({
  prompt: "You're a helpful assistant.", // Example prompt
  voice: {
    provider: "elevenlabs", // Voice provider
    voice_id: "voice-id" // Replace 'voice-id' with the ID of the desired voice
  },
  language: "<language_code>", // optional - use language code such as en, es
  tools: [
    {
      name: "get_user_data",
      description: "",
      webhook: "https://...",
      header: {
        "Content-Type": "application/json",
        "Authorization": ""
      },
      params: [
        {
          name: "",
          type: "string" | "number" | "boolean",
          description: "",
          required: true
        }
      ]
    }
  ], // Replace with actual function calls you need
  custom_llm_websocket: "wss://...", // optional - enable custom llm
  llm: "", // optional - choose llm model. Ex: gpt-4o, llama-3-70b
}, metadata: {});
```

To obtain the voice_id, use this API to acquire the complete list of voices: https://api-west.millis.ai:8080/voices

### 4. Stop a Conversation:

```js
msClient.stop();
```

### 5. Setup event listener:

```js
    msClient.on("onopen", () => {
      // When the client connected to the server
    });

    msClient.on("onready", () => {
      // When the conversation is ready
    });

    msClient.on("onaudio", (audio: Uint8Array) => {
      // Incoming audio chunk
    });

    msClient.on("analyzer", (analyzer: AnalyserNode) => {
      // AnalyserNode that you can use for audio animation
    });

    msClient.on("onclose", (event) => {
      // When the connection is closed
    });

    msClient.on("onerror", (error) => {
      // An error occurred
    });
```

## Support

If you encounter any issues or have questions, please reach out to us directly at thach@millis.ai.
